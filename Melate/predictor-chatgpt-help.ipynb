{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8 21 24 34 52 56 31]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "numeros = np.random.choice(range(1, 57), size=7, replace=False)\n",
    "print(numeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[42, 40, 17, 41, 29, 12, 28], [10, 50, 37, 53, 33, 55, 22], [21, 15, 9, 12, 13, 18, 19], [23, 22, 55, 54, 15, 12, 20], [36, 47, 34, 21, 50, 2, 1], [5, 4, 29, 40, 25, 13, 22], [34, 55, 27, 14, 11, 17, 33], [11, 29, 4, 33, 16, 27, 2], [15, 2, 54, 18, 45, 28, 27], [16, 25, 28, 36, 54, 23, 8]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "resultados = []\n",
    "for i in range(10):\n",
    "    numeros = np.random.choice(range(1, 57), size=7, replace=False)\n",
    "    resultados.append(list(numeros))\n",
    "\n",
    "print(resultados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'numbers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2894\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2895\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2896\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'numbers'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-36dbed4b7a2a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m# Preprocesamiento de datos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mscaler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_range\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mscaled_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'numbers'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m# Creación de secuencias de tiempo para usar en el modelo LSTM\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2900\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2901\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2902\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2903\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2904\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2895\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2896\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2897\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2898\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2899\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'numbers'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "import math\n",
    "\n",
    "# Carga los datos del archivo CSV en un DataFrame de Pandas\n",
    "#data = pd.read_csv('lottery_numbers.csv')\n",
    "data = pd.read_csv('https://drive.google.com/uc?id=1FHpAo8IbpDiu97lcAC4jt98agW5SsUTk')\n",
    "\n",
    "\n",
    "# Preprocesamiento de datos\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(data['numbers'].values.reshape(-1, 1))\n",
    "\n",
    "# Creación de secuencias de tiempo para usar en el modelo LSTM\n",
    "seq_length = 7\n",
    "x_data = []\n",
    "y_data = []\n",
    "for i in range(len(scaled_data)-seq_length):\n",
    "    x_data.append(scaled_data[i:i+seq_length, 0])\n",
    "    y_data.append(scaled_data[i+seq_length, 0])\n",
    "x_data, y_data = np.array(x_data), np.array(y_data)\n",
    "x_data = np.reshape(x_data, (x_data.shape[0], x_data.shape[1], 1))\n",
    "\n",
    "# División de datos en conjuntos de entrenamiento y prueba\n",
    "train_size = int(len(x_data) * 0.67)\n",
    "test_size = len(x_data) - train_size\n",
    "train_x, test_x = x_data[0:train_size,:], x_data[train_size:len(x_data),:]\n",
    "train_y, test_y = y_data[0:train_size], y_data[train_size:len(y_data)]\n",
    "\n",
    "# Definición del modelo LSTM utilizando la biblioteca de Keras\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(seq_length, 1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "# Entrenamiento del modelo LSTM\n",
    "model.fit(train_x, train_y, epochs=100, batch_size=32)\n",
    "\n",
    "# Utilización del modelo entrenado para hacer predicciones de los números ganadores de la lotería\n",
    "predictions = model.predict(test_x)\n",
    "predictions = scaler.inverse_transform(predictions)\n",
    "\n",
    "# Evaluación de la precisión del modelo\n",
    "rmse = math.sqrt(np.mean(((predictions - test_y) ** 2)))\n",
    "print(\"RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "SavedModel file does not exist at: lottery_model.h5/{saved_model.pbtxt|saved_model.pb}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-1012bcb22c55>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# cargar el modelo entrenado previamente\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'lottery_model.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# leer los datos del CSV\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\save.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[0;32m    209\u001b[0m       \u001b[0mfilepath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpath_to_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m         \u001b[0mloader_impl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_saved_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0msaved_model_load\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\saved_model\\loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model\u001b[1;34m(export_dir)\u001b[0m\n\u001b[0;32m    109\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Cannot parse file %s: %s.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpath_to_pbtxt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m     raise IOError(\"SavedModel file does not exist at: %s/{%s|%s}\" %\n\u001b[0m\u001b[0;32m    112\u001b[0m                   (export_dir,\n\u001b[0;32m    113\u001b[0m                    \u001b[0mconstants\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSAVED_MODEL_FILENAME_PBTXT\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: SavedModel file does not exist at: lottery_model.h5/{saved_model.pbtxt|saved_model.pb}"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "\n",
    "# cargar el modelo entrenado previamente\n",
    "model = load_model('lottery_model.h5')\n",
    "\n",
    "# leer los datos del CSV\n",
    "data = pd.read_csv('https://drive.google.com/uc?id=1FHpAo8IbpDiu97lcAC4jt98agW5SsUTk')\n",
    "\n",
    "# filtrar los datos para el año 2022\n",
    "data_2022 = data[data['FECHA'].str.contains('2022')]\n",
    "\n",
    "# convertir los números de cada sorteo en una matriz numpy\n",
    "draws = data_2022.iloc[:, 1:8].to_numpy()\n",
    "\n",
    "# normalizar los datos\n",
    "max_number = 56\n",
    "draws = draws / max_number\n",
    "\n",
    "# predecir el siguiente sorteo\n",
    "next_draw = model.predict(np.array([draws]))\n",
    "\n",
    "# desnormalizar los datos y obtener los números ganadores\n",
    "winning_numbers = (next_draw * max_number).astype(int)[0]\n",
    "\n",
    "print(\"Posibles números ganadores para el próximo sorteo:\")\n",
    "print(winning_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "75/75 [==============================] - 2s 4ms/step - loss: 0.0196\n",
      "Epoch 2/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0171\n",
      "Epoch 3/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0166\n",
      "Epoch 4/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0167\n",
      "Epoch 5/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0171\n",
      "Epoch 6/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0174\n",
      "Epoch 7/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0167\n",
      "Epoch 8/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0169\n",
      "Epoch 9/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 10/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0166\n",
      "Epoch 11/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0167\n",
      "Epoch 12/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0168\n",
      "Epoch 13/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0183\n",
      "Epoch 14/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0168\n",
      "Epoch 15/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0167\n",
      "Epoch 16/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 17/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0171\n",
      "Epoch 18/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 19/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0169\n",
      "Epoch 20/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 21/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0171\n",
      "Epoch 22/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0172\n",
      "Epoch 23/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0171\n",
      "Epoch 24/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 25/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0174\n",
      "Epoch 26/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0178\n",
      "Epoch 27/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0173\n",
      "Epoch 28/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 29/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0176\n",
      "Epoch 30/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0169\n",
      "Epoch 31/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0162\n",
      "Epoch 32/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0167\n",
      "Epoch 33/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0173\n",
      "Epoch 34/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0169\n",
      "Epoch 35/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0173\n",
      "Epoch 36/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 37/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0181\n",
      "Epoch 38/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0171\n",
      "Epoch 39/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0168\n",
      "Epoch 40/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 41/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0182\n",
      "Epoch 42/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 43/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0176\n",
      "Epoch 44/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 45/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0168\n",
      "Epoch 46/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0170\n",
      "Epoch 47/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0171\n",
      "Epoch 48/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0173\n",
      "Epoch 49/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0174\n",
      "Epoch 50/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0166\n",
      "Epoch 51/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0169\n",
      "Epoch 52/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0176\n",
      "Epoch 53/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0174\n",
      "Epoch 54/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0169\n",
      "Epoch 55/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0171\n",
      "Epoch 56/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 57/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0158\n",
      "Epoch 58/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0176\n",
      "Epoch 59/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0170\n",
      "Epoch 60/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0160\n",
      "Epoch 61/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0168\n",
      "Epoch 62/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0170\n",
      "Epoch 63/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0155A: 0s - loss: 0.0\n",
      "Epoch 64/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0168\n",
      "Epoch 65/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0182\n",
      "Epoch 66/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0172\n",
      "Epoch 67/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0164\n",
      "Epoch 68/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0173\n",
      "Epoch 69/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0162\n",
      "Epoch 70/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0171\n",
      "Epoch 71/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0171\n",
      "Epoch 72/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0169\n",
      "Epoch 73/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0176\n",
      "Epoch 74/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0166\n",
      "Epoch 75/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0159\n",
      "Epoch 76/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0176\n",
      "Epoch 77/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0173\n",
      "Epoch 78/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0171\n",
      "Epoch 79/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0172\n",
      "Epoch 80/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 81/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0162\n",
      "Epoch 82/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 83/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0173\n",
      "Epoch 84/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 85/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0173\n",
      "Epoch 86/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 87/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0176\n",
      "Epoch 88/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0171\n",
      "Epoch 89/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0159\n",
      "Epoch 90/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0157\n",
      "Epoch 91/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0173\n",
      "Epoch 92/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0160\n",
      "Epoch 93/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 94/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0167\n",
      "Epoch 95/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0162\n",
      "Epoch 96/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0172\n",
      "Epoch 97/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0166\n",
      "Epoch 98/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0164\n",
      "Epoch 99/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0168\n",
      "Epoch 100/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0178\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "non-broadcastable output operand with shape (1172,1) doesn't match the broadcast shape (1172,7)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-1b6b57225ea2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;31m# Utilización del modelo entrenado para hacer predicciones de los números ganadores de la lotería\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;31m# Evaluación de la precisión del modelo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36minverse_transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    430\u001b[0m                         force_all_finite=\"allow-nan\")\n\u001b[0;32m    431\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m/=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscale_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: non-broadcastable output operand with shape (1172,1) doesn't match the broadcast shape (1172,7)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "import math\n",
    "\n",
    "# Carga los datos del archivo CSV en un DataFrame de Pandas\n",
    "#data = pd.read_csv('lottery_numbers.csv')\n",
    "data = pd.read_csv('https://drive.google.com/uc?id=1FHpAo8IbpDiu97lcAC4jt98agW5SsUTk')\n",
    "\n",
    "\n",
    "# Preprocesamiento de datos\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(data[['R1','R2','R3','R4','R5','R6','R7']].values)\n",
    "\n",
    "# Creación de secuencias de tiempo para usar en el modelo LSTM\n",
    "seq_length = 7\n",
    "x_data = []\n",
    "y_data = []\n",
    "for i in range(len(scaled_data)-seq_length):\n",
    "    x_data.append(scaled_data[i:i+seq_length, 0])\n",
    "    y_data.append(scaled_data[i+seq_length, 0])\n",
    "x_data, y_data = np.array(x_data), np.array(y_data)\n",
    "x_data = np.reshape(x_data, (x_data.shape[0], x_data.shape[1], 1))\n",
    "\n",
    "# División de datos en conjuntos de entrenamiento y prueba\n",
    "train_size = int(len(x_data) * 0.67)\n",
    "test_size = len(x_data) - train_size\n",
    "train_x, test_x = x_data[0:train_size,:], x_data[train_size:len(x_data),:]\n",
    "train_y, test_y = y_data[0:train_size], y_data[train_size:len(y_data)]\n",
    "\n",
    "# Definición del modelo LSTM utilizando la biblioteca de Keras\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(seq_length, 1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "# Entrenamiento del modelo LSTM\n",
    "model.fit(train_x, train_y, epochs=100, batch_size=32)\n",
    "\n",
    "# Utilización del modelo entrenado para hacer predicciones de los números ganadores de la lotería\n",
    "predictions = model.predict(test_x)\n",
    "predictions = scaler.inverse_transform(predictions)\n",
    "\n",
    "# Evaluación de la precisión del modelo\n",
    "rmse = math.sqrt(np.mean(((predictions - test_y) ** 2)))\n",
    "print(\"RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "75/75 [==============================] - 2s 4ms/step - loss: 0.1044\n",
      "Epoch 2/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0270\n",
      "Epoch 3/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0272\n",
      "Epoch 4/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0273\n",
      "Epoch 5/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0277\n",
      "Epoch 6/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0269\n",
      "Epoch 7/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0263\n",
      "Epoch 8/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0268\n",
      "Epoch 9/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0261\n",
      "Epoch 10/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0273\n",
      "Epoch 11/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0273\n",
      "Epoch 12/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0261\n",
      "Epoch 13/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0270\n",
      "Epoch 14/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0268\n",
      "Epoch 15/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0259\n",
      "Epoch 16/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0262\n",
      "Epoch 17/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0269\n",
      "Epoch 18/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0266\n",
      "Epoch 19/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0270\n",
      "Epoch 20/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0267\n",
      "Epoch 21/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0265\n",
      "Epoch 22/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0266\n",
      "Epoch 23/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0264\n",
      "Epoch 24/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0262\n",
      "Epoch 25/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0263\n",
      "Epoch 26/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0271\n",
      "Epoch 27/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0272\n",
      "Epoch 28/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0264\n",
      "Epoch 29/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0267\n",
      "Epoch 30/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0263\n",
      "Epoch 31/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0265\n",
      "Epoch 32/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0259\n",
      "Epoch 33/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0266\n",
      "Epoch 34/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0263\n",
      "Epoch 35/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0260\n",
      "Epoch 36/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0274\n",
      "Epoch 37/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0267\n",
      "Epoch 38/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0257\n",
      "Epoch 39/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0264\n",
      "Epoch 40/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0268\n",
      "Epoch 41/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0269\n",
      "Epoch 42/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0272\n",
      "Epoch 43/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0262\n",
      "Epoch 44/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0263\n",
      "Epoch 45/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0264\n",
      "Epoch 46/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0258\n",
      "Epoch 47/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0269\n",
      "Epoch 48/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0268\n",
      "Epoch 49/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0268\n",
      "Epoch 50/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0262\n",
      "Epoch 51/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0266\n",
      "Epoch 52/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0261\n",
      "Epoch 53/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0264\n",
      "Epoch 54/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0262\n",
      "Epoch 55/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0259\n",
      "Epoch 56/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0266\n",
      "Epoch 57/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0273\n",
      "Epoch 58/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0257\n",
      "Epoch 59/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0263\n",
      "Epoch 60/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0268\n",
      "Epoch 61/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0268\n",
      "Epoch 62/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0261\n",
      "Epoch 63/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0263\n",
      "Epoch 64/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0265\n",
      "Epoch 65/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0264\n",
      "Epoch 66/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0273\n",
      "Epoch 67/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0259\n",
      "Epoch 68/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0265\n",
      "Epoch 69/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0259\n",
      "Epoch 70/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0258\n",
      "Epoch 71/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0266\n",
      "Epoch 72/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0262\n",
      "Epoch 73/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0267\n",
      "Epoch 74/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0263\n",
      "Epoch 75/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0255\n",
      "Epoch 76/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0261\n",
      "Epoch 77/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0258\n",
      "Epoch 78/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0268\n",
      "Epoch 79/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0261\n",
      "Epoch 80/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0262\n",
      "Epoch 81/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0259\n",
      "Epoch 82/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0265\n",
      "Epoch 83/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0267\n",
      "Epoch 84/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0266\n",
      "Epoch 85/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0266\n",
      "Epoch 86/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0257\n",
      "Epoch 87/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0267\n",
      "Epoch 88/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0261\n",
      "Epoch 89/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0259\n",
      "Epoch 90/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0263\n",
      "Epoch 91/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0261\n",
      "Epoch 92/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0261\n",
      "Epoch 93/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0262\n",
      "Epoch 94/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0265\n",
      "Epoch 95/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0268\n",
      "Epoch 96/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0261\n",
      "Epoch 97/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0264\n",
      "Epoch 98/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0259\n",
      "Epoch 99/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0265\n",
      "Epoch 100/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0269\n",
      "RMSE: 29.634611913711545\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "import math\n",
    "\n",
    "# Carga los datos del archivo CSV en un DataFrame de Pandas\n",
    "#data = pd.read_csv('lottery_numbers.csv')\n",
    "data = pd.read_csv('https://drive.google.com/uc?id=1FHpAo8IbpDiu97lcAC4jt98agW5SsUTk')\n",
    "\n",
    "\n",
    "# Preprocesamiento de datos\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(data[['R1','R2','R3','R4','R5','R6','R7']].values)\n",
    "\n",
    "# Creación de secuencias de tiempo para usar en el modelo LSTM\n",
    "seq_length = 7\n",
    "x_data = []\n",
    "y_data = []\n",
    "for i in range(len(scaled_data)-seq_length):\n",
    "    x_data.append(scaled_data[i:i+seq_length, :])\n",
    "    y_data.append(scaled_data[i+seq_length, :])\n",
    "x_data, y_data = np.array(x_data), np.array(y_data)\n",
    "x_data = np.reshape(x_data, (x_data.shape[0], x_data.shape[1], 7))\n",
    "\n",
    "# División de datos en conjuntos de entrenamiento y prueba\n",
    "train_size = int(len(x_data) * 0.67)\n",
    "test_size = len(x_data) - train_size\n",
    "train_x, test_x = x_data[0:train_size,:,:], x_data[train_size:len(x_data),:,:]\n",
    "train_y, test_y = y_data[0:train_size,:], y_data[train_size:len(y_data),:]\n",
    "\n",
    "# Definición del modelo LSTM utilizando la biblioteca de Keras\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(seq_length, 7)))\n",
    "model.add(Dense(7))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "# Entrenamiento del modelo LSTM\n",
    "model.fit(train_x, train_y, epochs=100, batch_size=32)\n",
    "\n",
    "# Utilización del modelo entrenado para hacer predicciones de los números ganadores de la lotería\n",
    "predictions = model.predict(test_x)\n",
    "predictions = scaler.inverse_transform(predictions)\n",
    "\n",
    "# Evaluación de la precisión del modelo\n",
    "rmse = math.sqrt(np.mean(((predictions - test_y) ** 2)))\n",
    "print(\"RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "75/75 [==============================] - 2s 4ms/step - loss: 0.0633\n",
      "Epoch 2/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0277\n",
      "Epoch 3/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0268\n",
      "Epoch 4/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0274\n",
      "Epoch 5/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0271\n",
      "Epoch 6/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0272\n",
      "Epoch 7/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0268\n",
      "Epoch 8/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0269\n",
      "Epoch 9/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0266\n",
      "Epoch 10/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0266\n",
      "Epoch 11/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0264\n",
      "Epoch 12/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0268\n",
      "Epoch 13/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0264\n",
      "Epoch 14/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0266\n",
      "Epoch 15/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0272\n",
      "Epoch 16/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0262\n",
      "Epoch 17/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0270\n",
      "Epoch 18/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0259\n",
      "Epoch 19/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0274\n",
      "Epoch 20/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0268\n",
      "Epoch 21/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0270\n",
      "Epoch 22/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0270\n",
      "Epoch 23/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0271\n",
      "Epoch 24/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0266\n",
      "Epoch 25/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0272\n",
      "Epoch 26/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0268\n",
      "Epoch 27/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0265A: 0s - loss: 0.\n",
      "Epoch 28/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0266\n",
      "Epoch 29/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0267\n",
      "Epoch 30/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0264\n",
      "Epoch 31/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0273\n",
      "Epoch 32/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0272\n",
      "Epoch 33/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0268A: 0s - loss: 0.02\n",
      "Epoch 34/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0267\n",
      "Epoch 35/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0259\n",
      "Epoch 36/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0270\n",
      "Epoch 37/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0255\n",
      "Epoch 38/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0267\n",
      "Epoch 39/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0260\n",
      "Epoch 40/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0269\n",
      "Epoch 41/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0264\n",
      "Epoch 42/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0259\n",
      "Epoch 43/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0265\n",
      "Epoch 44/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0264\n",
      "Epoch 45/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0268\n",
      "Epoch 46/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0259\n",
      "Epoch 47/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0268\n",
      "Epoch 48/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0261\n",
      "Epoch 49/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0266\n",
      "Epoch 50/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0271\n",
      "Epoch 51/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0265\n",
      "Epoch 52/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0263\n",
      "Epoch 53/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0262\n",
      "Epoch 54/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0263\n",
      "Epoch 55/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0258\n",
      "Epoch 56/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0270\n",
      "Epoch 57/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0267\n",
      "Epoch 58/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0261\n",
      "Epoch 59/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0269\n",
      "Epoch 60/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0271\n",
      "Epoch 61/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0264\n",
      "Epoch 62/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0269\n",
      "Epoch 63/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0258\n",
      "Epoch 64/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0269\n",
      "Epoch 65/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0264\n",
      "Epoch 66/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0262\n",
      "Epoch 67/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0258\n",
      "Epoch 68/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0266\n",
      "Epoch 69/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0260\n",
      "Epoch 70/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0261\n",
      "Epoch 71/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0266\n",
      "Epoch 72/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0265\n",
      "Epoch 73/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0262\n",
      "Epoch 74/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0262\n",
      "Epoch 75/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0263\n",
      "Epoch 76/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0268\n",
      "Epoch 77/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0259\n",
      "Epoch 78/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0258\n",
      "Epoch 79/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0269\n",
      "Epoch 80/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0260\n",
      "Epoch 81/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0260\n",
      "Epoch 82/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0255\n",
      "Epoch 83/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0263\n",
      "Epoch 84/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0265\n",
      "Epoch 85/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0264\n",
      "Epoch 86/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0254\n",
      "Epoch 87/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0263\n",
      "Epoch 88/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0262\n",
      "Epoch 89/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0261\n",
      "Epoch 90/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0268\n",
      "Epoch 91/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0259\n",
      "Epoch 92/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0260\n",
      "Epoch 93/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0261\n",
      "Epoch 94/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0267\n",
      "Epoch 95/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0258\n",
      "Epoch 96/100\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0267\n",
      "Epoch 97/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0265\n",
      "Epoch 98/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0267\n",
      "Epoch 99/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0270\n",
      "Epoch 100/100\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0265\n",
      "RMSE para el número 1 : 8.51495156522548\n",
      "RMSE para el número 2 : 14.971791727025698\n",
      "RMSE para el número 3 : 22.77613543854463\n",
      "RMSE para el número 4 : 30.795797017978547\n",
      "RMSE para el número 5 : 38.67952924788873\n",
      "RMSE para el número 6 : 46.475746678203755\n",
      "RMSE para el número 7 : 27.433053640696034\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "import math\n",
    "\n",
    "# Carga los datos del archivo CSV en un DataFrame de Pandas\n",
    "#data = pd.read_csv('lottery_numbers.csv')\n",
    "data = pd.read_csv('https://drive.google.com/uc?id=1FHpAo8IbpDiu97lcAC4jt98agW5SsUTk')\n",
    "\n",
    "# Preprocesamiento de datos\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(data[['R1','R2','R3','R4','R5','R6','R7']].values)\n",
    "\n",
    "# Creación de secuencias de tiempo para usar en el modelo LSTM\n",
    "seq_length = 7\n",
    "x_data = []\n",
    "y_data = []\n",
    "for i in range(len(scaled_data)-seq_length):\n",
    "    x_data.append(scaled_data[i:i+seq_length, :])\n",
    "    y_data.append(scaled_data[i+seq_length, :])\n",
    "x_data, y_data = np.array(x_data), np.array(y_data)\n",
    "\n",
    "# División de datos en conjuntos de entrenamiento y prueba\n",
    "train_size = int(len(x_data) * 0.67)\n",
    "test_size = len(x_data) - train_size\n",
    "train_x, test_x = x_data[0:train_size,:,:], x_data[train_size:len(x_data),:,:]\n",
    "train_y, test_y = y_data[0:train_size,:], y_data[train_size:len(y_data),:]\n",
    "\n",
    "# Definición del modelo LSTM utilizando la biblioteca de Keras\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(seq_length, 7)))\n",
    "model.add(Dense(7))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "# Entrenamiento del modelo LSTM\n",
    "model.fit(train_x, train_y, epochs=100, batch_size=32)\n",
    "\n",
    "# Utilización del modelo entrenado para hacer predicciones de los números ganadores de la lotería\n",
    "predictions = model.predict(test_x)\n",
    "predictions = scaler.inverse_transform(predictions)\n",
    "\n",
    "# Evaluación de la precisión del modelo para cada uno de los siete números\n",
    "for i in range(7):\n",
    "    rmse = math.sqrt(np.mean(((predictions[:, i] - test_y[:, i]) ** 2)))\n",
    "    print(\"RMSE para el número\", i+1, \":\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3561,3,10,13,22,29,30,46,2022-03-16\n",
    "3560,2,23,24,28,50,53,12,2022-03-13\n",
    "3559,9,17,29,37,49,50,2,2022-03-11\n",
    "3558,6,13,16,27,29,55,15,2022-03-09"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
